{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7552584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f28f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from transformers import ResNetModel\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82697ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import ResNetModel\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchvision.transforms import v2\n",
    "import torch\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b723e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10800\n",
      "1351\n",
      "1350\n"
     ]
    }
   ],
   "source": [
    "# DEVICE = 'cuda'\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "\n",
    "base_path = 'archive/'\n",
    "img_path = f'{base_path}Food Images/Food Images/'\n",
    "cap_path = f'{base_path}Food Ingredients and Recipe Dataset with Image Name Mapping.csv'\n",
    "\n",
    "data = pd.read_csv(cap_path)\n",
    "partitions = np.load(\"datasets/Food_Images/food_partitions.npy\", allow_pickle=True).item()\n",
    "print(len(partitions[\"train\"]))  # Access train partition\n",
    "print(len(partitions[\"test\"]))   # Access test partition\n",
    "print(len(partitions[\"valid\"])) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff827a9",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6613d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10797\n"
     ]
    }
   ],
   "source": [
    "dropped_indices = data[data[\"Title\"].isna()].index  # Get indices of dropped rows\n",
    "partitions['train'] = [idx for idx in partitions['train'] if idx not in dropped_indices]\n",
    "print(len(partitions['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aef343d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13496"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.dropna(subset=[\"Title\"])\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d9d69e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13582\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "image_folder = f\"archive/Food Images/Food Images\"\n",
    "# valid_images = list(set(os.listdir(image_folder)))\n",
    "\n",
    "valid_images = list({os.path.splitext(f)[0] for f in os.listdir(image_folder)})\n",
    "\n",
    "print(len(valid_images))\n",
    "# print(valid_images[:5])\n",
    "# print(data[\"Image_Name\"].head())\n",
    "      \n",
    "data = data[data[\"Image_Name\"].isin(valid_images)]\n",
    "\n",
    "# Reset index after filtering\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427ed956",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indices = set(data.index)  # These are the indices that remain after filtering\n",
    "\n",
    "partitions['train'] = [idx for idx in partitions['train'] if idx in valid_indices]\n",
    "partitions['valid'] = [idx for idx in partitions['valid'] if idx in valid_indices]\n",
    "partitions['test'] = [idx for idx in partitions['test'] if idx in valid_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1750bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "174\n",
      "37\n",
      "147\n"
     ]
    }
   ],
   "source": [
    "# unique_chars_1 = set(\"\".join(data[\"Ingredients\"].astype(str)))\n",
    "# unique_chars_2 = set(\"\".join(data[\"Instructions\"].astype(str)))\n",
    "# unique_chars_3 = set(\"\".join(data[\"Image_Name\"].astype(str)))\n",
    "# unique_chars_4 = set(\"\".join(data[\"Cleaned_Ingredients\"].astype(str)))\n",
    "\n",
    "# print(len(unique_chars_1))\n",
    "# print(len(unique_chars_2))\n",
    "# print(len(unique_chars_3))\n",
    "# print(len(unique_chars_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393b1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "# Normalize and remove unwanted characters\n",
    "def clean_text(text):\n",
    "    text = unicodedata.normalize(\"NFKD\", text)  # Normalize Unicode\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode(\"ascii\")  # Remove non-ASCII chars\n",
    "    return text\n",
    "\n",
    "# Apply cleaning to the Title column\n",
    "data[\"Title\"] = data[\"Title\"].astype(str).apply(clean_text)\n",
    "\n",
    "# Extract unique characters\n",
    "chars = list(set(\"\".join(data[\"Title\"])))\n",
    "\n",
    "# Ensure special tokens are first\n",
    "chars = ['<SOS>', '<EOS>', '<PAD>'] + sorted(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b09b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chars = ['<SOS>', '<EOS>', '<PAD>', ' ', '!', '\"', '#', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n",
    " \n",
    "NUM_CHAR = len(chars)\n",
    "idx2char = {k: v for k, v in enumerate(chars)}\n",
    "char2idx = {v: k for k, v in enumerate(chars)}\n",
    "\n",
    "TEXT_MAX_LEN = 201"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff6590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    def __init__(self, data, partition):\n",
    "        self.data = data\n",
    "        self.partition = partition\n",
    "        self.num_captions = 5\n",
    "        self.max_len = TEXT_MAX_LEN\n",
    "        self.img_proc = torch.nn.Sequential(\n",
    "            v2.ToImage(),\n",
    "            v2.ToDtype(torch.float32, scale=True),\n",
    "            v2.Resize((224, 224), antialias=True),\n",
    "            v2.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.partition)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        real_idx = self.partition[idx]  # Row index in dataset\n",
    "        item = self.data.iloc[real_idx]  # Get row\n",
    "                \n",
    "        img_name = item.Image_Name + '.jpg'\n",
    "        # print(img_name)\n",
    "        img = Image.open(f'{img_path}{img_name}').convert('RGB')\n",
    "        img = self.img_proc(img)\n",
    "        \n",
    "        caption = item[\"Title\"]\n",
    "        cap_list = list(caption)\n",
    "\n",
    "        final_list = [chars[0]]\n",
    "        final_list.extend(cap_list)\n",
    "        final_list.extend([chars[1]])\n",
    "        gap = self.max_len - len(final_list)\n",
    "        final_list.extend([chars[2]]*gap)\n",
    "\n",
    "        missing_chars = [c for c in final_list if c not in char2idx]\n",
    "        if missing_chars:\n",
    "            print(f\"Missing characters: {set(missing_chars)}\")\n",
    "\n",
    "        for char in missing_chars:\n",
    "            if char not in char2idx:\n",
    "                char2idx[char] = len(char2idx)  # Assign a new index\n",
    "\n",
    "        cap_idx = [char2idx[i] for i in final_list]\n",
    "\n",
    "        # return img, cap_idx\n",
    "        return img, torch.tensor(cap_idx, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b652abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = ResNetModel.from_pretrained('microsoft/resnet-18').to(DEVICE)\n",
    "        self.gru = nn.GRU(512, 512, num_layers=1)\n",
    "        self.proj = nn.Linear(512, NUM_CHAR)\n",
    "        self.embed = nn.Embedding(NUM_CHAR, 512)\n",
    "        self.num_classes = NUM_CHAR\n",
    "\n",
    "    def forward(self, img, captions=None, teacher_forcing_ratio=0.5):\n",
    "        batch_size = img.shape[0]\n",
    "        feat = self.resnet(img)\n",
    "        feat = feat.pooler_output.squeeze(-1).squeeze(-1).unsqueeze(0)  # (1, batch, 512)\n",
    "\n",
    "        start_token = torch.full((batch_size,), char2idx['<SOS>'], dtype=torch.long, device=DEVICE)\n",
    "        start_embed = self.embed(start_token).unsqueeze(0)  # (1, batch, 512)\n",
    "\n",
    "        hidden = feat\n",
    "        inp = start_embed\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(TEXT_MAX_LEN):  # Exclude <SOS>\n",
    "            out, hidden = self.gru(inp, hidden)\n",
    "            logits = self.proj(out[-1])  # (batch, NUM_CHAR)\n",
    "\n",
    "            outputs.append(logits.unsqueeze(1))  # Store timestep output\n",
    "\n",
    "            # Decide whether to use teacher forcing\n",
    "            if captions is not None and torch.rand(1).item() < teacher_forcing_ratio:\n",
    "                inp = self.embed(captions[:, t]).unsqueeze(0)  # Use ground truth token\n",
    "            else:\n",
    "                pred = logits.argmax(dim=1)\n",
    "                inp = self.embed(pred).unsqueeze(0)  # Use model prediction\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)  # (batch, seq_len, NUM_CHAR)\n",
    "        return outputs.permute(0, 2, 1)  # (batch, NUM_CHAR, seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82acf476",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_19764\\108332190.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  caption1 = torch.tensor(caption1)\n",
      "C:\\Users\\Dell\\AppData\\Local\\Temp\\ipykernel_19764\\108332190.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  caption2 = torch.tensor(caption2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6790, device='cuda:0', grad_fn=<NllLoss2DBackward0>)\n"
     ]
    }
   ],
   "source": [
    "'''A simple example to calculate loss of a single batch (size 2)'''\n",
    "dataset = Data(data, partitions['train'])\n",
    "\n",
    "img1, caption1 = next(iter(dataset))\n",
    "\n",
    "img2, caption2 = next(iter(dataset))\n",
    "\n",
    "caption1 = torch.tensor(caption1)\n",
    "caption2 = torch.tensor(caption2)\n",
    "img = torch.cat((img1.unsqueeze(0), img2.unsqueeze(0)))\n",
    "caption = torch.cat((caption1.unsqueeze(0), caption2.unsqueeze(0)))\n",
    "img, caption = img.to(DEVICE), caption.to(DEVICE)\n",
    "model = Model().to(DEVICE)\n",
    "pred = model(img)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "loss = crit(pred, caption)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ae4e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Device: 0\n",
      "Device Name: NVIDIA GeForce GTX 1660 Ti with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "print(\"Current Device:\", torch.cuda.current_device())\n",
    "print(\"Device Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cc077a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Tensor successfully moved to: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# torch.cuda.empty_cache()\n",
    "# torch.cuda.ipc_collect()\n",
    "# torch.cuda.reset_max_memory_allocated()\n",
    "# torch.cuda.reset_max_memory_cached()\n",
    "# torch.cuda.synchronize()\n",
    "\n",
    "DEVICE = torch.device(\"cuda\")\n",
    "print(\"Using device:\", DEVICE)\n",
    "\n",
    "try:\n",
    "    x = torch.rand(3, 3).to(DEVICE)\n",
    "    print(\"Tensor successfully moved to:\", x.device)\n",
    "except Exception as e:\n",
    "    print(\"Error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3606f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\Dell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'bleu': 0.5946035575013605,\n",
       "  'precisions': [0.875, 0.7142857142857143, 0.5, 0.4],\n",
       "  'brevity_penalty': 1.0,\n",
       "  'length_ratio': 1.0,\n",
       "  'translation_length': 8,\n",
       "  'reference_length': 8},\n",
       " {'rouge1': 0.8571428571428571,\n",
       "  'rouge2': 0.6666666666666666,\n",
       "  'rougeL': 0.8571428571428571,\n",
       "  'rougeLsum': 0.8571428571428571},\n",
       " {'meteor': 0.864795918367347})"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''metrics'''\n",
    "bleu = evaluate.load('bleu')\n",
    "meteor = evaluate.load('meteor')\n",
    "rouge = evaluate.load('rouge')\n",
    "\n",
    "reference = [['A child in a pink dress is climbing up a set of stairs in an entry way .', 'A girl going into a wooden building .']]\n",
    "prediction = ['A girl goes into a wooden building .']\n",
    "\n",
    "res_b = bleu.compute(predictions=prediction, references=reference)\n",
    "res_r = rouge.compute(predictions=prediction, references=reference)\n",
    "res_m = meteor.compute(predictions=prediction, references=reference)\n",
    "\n",
    "res_b, res_r, res_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7595f1f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bleu': 0.4723665527410147,\n",
       "  'precisions': [1.0, 1.0, 1.0, 1.0],\n",
       "  'brevity_penalty': 0.4723665527410147,\n",
       "  'length_ratio': 0.5714285714285714,\n",
       "  'translation_length': 4,\n",
       "  'reference_length': 7},\n",
       " {'rouge1': 0.7272727272727273,\n",
       "  'rouge2': 0.6666666666666666,\n",
       "  'rougeL': 0.7272727272727273,\n",
       "  'rougeLsum': 0.7272727272727273},\n",
       " {'meteor': 0.5923507462686567})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = [['A child is running in the campus']]\n",
    "pred1 = ['A child is running']\n",
    "\n",
    "res_b = bleu.compute(predictions=pred1, references=ref)\n",
    "res_r = rouge.compute(predictions=pred1, references=ref)\n",
    "res_m = meteor.compute(predictions=pred1, references=ref)\n",
    "\n",
    "res_b, res_r, res_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe24da77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bleu': 0.0,\n",
       "  'precisions': [1.0, 1.0, 1.0, 0.0],\n",
       "  'brevity_penalty': 0.2635971381157267,\n",
       "  'length_ratio': 0.42857142857142855,\n",
       "  'translation_length': 3,\n",
       "  'reference_length': 7},\n",
       " {'rouge1': 0.6, 'rouge2': 0.5, 'rougeL': 0.6, 'rougeLsum': 0.6},\n",
       " {'meteor': 0.44612794612794615})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = [['A child is running in the campus']]\n",
    "pred1 = ['A child is']\n",
    "\n",
    "res_b = bleu.compute(predictions=pred1, references=ref)\n",
    "res_r = rouge.compute(predictions=pred1, references=ref)\n",
    "res_m = meteor.compute(predictions=pred1, references=ref)\n",
    "\n",
    "res_b, res_r, res_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1afd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'bleu': 0.0,\n",
       "  'precisions': [1.0, 0.5, 0.0, 0.0],\n",
       "  'brevity_penalty': 0.2635971381157267,\n",
       "  'length_ratio': 0.42857142857142855,\n",
       "  'translation_length': 3,\n",
       "  'reference_length': 7},\n",
       " {'rouge1': 0.6, 'rouge2': 0.25, 'rougeL': 0.6, 'rougeLsum': 0.6},\n",
       " {'meteor': 0.3872053872053872},\n",
       " {'meteor': 0.45454545454545453})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = [['A child is running in the campus']]\n",
    "pred1 = ['A child campus']\n",
    "\n",
    "res_b = bleu.compute(predictions=pred1, references=ref)\n",
    "res_r = rouge.compute(predictions=pred1, references=ref)\n",
    "res_m = meteor.compute(predictions=pred1, references=ref)\n",
    "res_m_sin = meteor.compute(predictions=pred1, references=ref, gamma=0) # no penalty by setting gamma to 0\n",
    "\n",
    "res_b, res_r, res_m, res_m_sin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980bac05",
   "metadata": {},
   "source": [
    "Final metric we use for challenge 3: BLEU1, BLEU2, ROUGE-L, METEOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5433823c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BLEU-1:26.4%, BLEU2:18.6%, ROUGE-L:60.0%, METEOR:38.7%'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ref = [['A child is running in the campus']]\n",
    "pred1 = ['A child campus']\n",
    "\n",
    "bleu1 = bleu.compute(predictions=pred1, references=ref, max_order=1)\n",
    "bleu2 = bleu.compute(predictions=pred1, references=ref, max_order=2)\n",
    "res_r = rouge.compute(predictions=pred1, references=ref)\n",
    "res_m = meteor.compute(predictions=pred1, references=ref)\n",
    "\n",
    "f\"BLEU-1:{bleu1['bleu']*100:.1f}%, BLEU2:{bleu2['bleu']*100:.1f}%, ROUGE-L:{res_r['rougeL']*100:.1f}%, METEOR:{res_m['meteor']*100:.1f}%\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdbf5d9d",
   "metadata": {},
   "source": [
    "Now it is your turn! Try to finish the code below to run the train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad20cf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = ResNetModel.from_pretrained('microsoft/resnet-18').to(DEVICE)\n",
    "        self.gru = nn.GRU(512, 512, num_layers=1)\n",
    "        self.proj = nn.Linear(512, NUM_CHAR)\n",
    "        self.embed = nn.Embedding(NUM_CHAR, 512)\n",
    "        self.num_classes = NUM_CHAR\n",
    "\n",
    "    def forward(self, img, captions=None, teacher_forcing_ratio=0.5):\n",
    "        batch_size = img.shape[0]\n",
    "        feat = self.resnet(img)\n",
    "        feat = feat.pooler_output.squeeze(-1).squeeze(-1).unsqueeze(0)  # (1, batch, 512)\n",
    "\n",
    "        start_token = torch.full((batch_size,), char2idx['<SOS>'], dtype=torch.long, device=DEVICE)\n",
    "        start_embed = self.embed(start_token).unsqueeze(0)  # (1, batch, 512)\n",
    "\n",
    "        hidden = feat\n",
    "        inp = start_embed\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(TEXT_MAX_LEN):  # Exclude <SOS>\n",
    "            out, hidden = self.gru(inp, hidden)\n",
    "            logits = self.proj(out[-1])  # (batch, NUM_CHAR)\n",
    "\n",
    "            outputs.append(logits.unsqueeze(1))  # Store timestep output\n",
    "\n",
    "            # Decide whether to use teacher forcing\n",
    "            if captions is not None and torch.rand(1).item() < teacher_forcing_ratio:\n",
    "                inp = self.embed(captions[:, t]).unsqueeze(0)  # Use ground truth token\n",
    "            else:\n",
    "                pred = logits.argmax(dim=1)\n",
    "                inp = self.embed(pred).unsqueeze(0)  # Use model prediction\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)  # (batch, seq_len, NUM_CHAR)\n",
    "        return outputs.permute(0, 2, 1)  # (batch, NUM_CHAR, seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f85e85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import os\n",
    "\n",
    "import wandb\n",
    "\n",
    "def decode_caption(indices, vocab):\n",
    "    return ''.join([vocab[idx] if idx < len(vocab) else '<UNK>' for idx in indices if idx not in [0]])\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Removes padding and special tokens, then strips whitespace.\"\"\"\n",
    "    return text.replace(\"<PAD>\", \"\").replace(\"<EOS>\", \"\").strip()\n",
    "\n",
    "def is_empty_prediction(pred_list):\n",
    "    \"\"\"Checks if any cleaned prediction is empty.\"\"\"\n",
    "    return any(len(clean_text(pred)) == 0 for pred in pred_list)\n",
    "\n",
    "def train(EPOCHS, batch_size=8, patience=5, teacher_forcing_ratio=0.5):\n",
    "    \n",
    "    wandb.init(project=\"captioning-model\", config={\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"batch_size\": batch_size,\n",
    "        \"learning_rate\": 1e-3,\n",
    "        \"teacher_forcing_ratio\": teacher_forcing_ratio\n",
    "    })\n",
    "\n",
    "    data_train = Data(data, partitions['train'])\n",
    "    data_valid = Data(data, partitions['valid'])\n",
    "    \n",
    "    dataloader_train = DataLoader(data_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    dataloader_valid = DataLoader(data_valid, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    print(\"DataLoader process is finished\")\n",
    "    \n",
    "    model = Model().to(DEVICE)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = StepLR(optimizer, step_size=10, gamma=0.1)  # Learning rate decay\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    \n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    os.makedirs(\"models/lstm_20\", exist_ok=True)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Starting epoch {epoch+1}\")\n",
    "        model.train()\n",
    "        train_loss, train_acc = train_one_epoch(model, optimizer, crit, dataloader_train, teacher_forcing_ratio)\n",
    "        \n",
    "        print(f'Epoch {epoch+1}/{EPOCHS} - Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}')\n",
    "        scheduler.step()\n",
    "\n",
    "        model.eval()\n",
    "        valid_loss, bleu1_score, bleu2_score, rouge_score, meteor_score = eval_epoch(model, crit, dataloader_valid)\n",
    "        print(f'Validation Loss: {valid_loss:.4f}')\n",
    "\n",
    "        # Log metrics to wandb\n",
    "        wandb.log({\n",
    "            # \"Epoch\": epoch + 1,\n",
    "            \"Train Loss\": train_loss,\n",
    "            \"Validation Loss\": valid_loss,\n",
    "            \"BLEU-1\": bleu1_score,\n",
    "            \"BLEU-2\": bleu2_score,\n",
    "            \"ROUGE-L\": rouge_score,\n",
    "            \"METEOR\": meteor_score\n",
    "        })\n",
    "\n",
    "        if valid_loss < best_val_loss:\n",
    "            best_val_loss = valid_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), f\"models/lstm_20/best_model_{epoch + 1}.pth\")\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered.\")\n",
    "            break\n",
    "\n",
    "    print(\"Training complete.\")\n",
    "\n",
    "\n",
    "def train_one_epoch(model, optimizer, crit, dataloader, teacher_forcing_ratio):\n",
    "\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    bleu1_score = 0\n",
    "    bleu2_score = 0\n",
    "    rouge_score = 0\n",
    "    meteor_score = 0\n",
    "\n",
    "    for imgs, captions in dataloader:\n",
    "        imgs, captions = imgs.to(DEVICE), captions.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        use_teacher_forcing = torch.rand(1).item() < teacher_forcing_ratio\n",
    "        outputs = model(imgs, captions if use_teacher_forcing else None)\n",
    "\n",
    "        loss = crit(outputs, captions)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        _, predicted = outputs.max(1)\n",
    "        \n",
    "        decoded_refs = [clean_text(decode_caption(caption.cpu().numpy(), chars)) for caption in captions]\n",
    "        decoded_preds = [clean_text(decode_caption(pred.cpu().numpy(), chars)) for pred in predicted]\n",
    "        \n",
    "        print(f\"Ref: {decoded_refs}\")\n",
    "        print(f\"Pred: {decoded_preds}\")\n",
    "\n",
    "        if is_empty_prediction(decoded_preds):\n",
    "            continue\n",
    "\n",
    "        bleu1 = bleu.compute(predictions=decoded_preds, references=[[ref] for ref in decoded_refs], max_order=1)\n",
    "        bleu2 = bleu.compute(predictions=decoded_preds, references=[[ref] for ref in decoded_refs], max_order=2)\n",
    "        res_r = rouge.compute(predictions=decoded_preds, references=decoded_refs)\n",
    "        res_m = meteor.compute(predictions=decoded_preds, references=decoded_refs)\n",
    "\n",
    "        # Accumulate scores\n",
    "        bleu1_score += bleu1[\"bleu\"]\n",
    "        bleu2_score += bleu2[\"bleu\"]\n",
    "        rouge_score += res_r[\"rougeL\"]\n",
    "        meteor_score += res_m[\"meteor\"]\n",
    "\n",
    "        print(f\"BLEU-1: {bleu1['bleu']:.4f}, BLEU-2: {bleu2['bleu']:.4f}, ROUGE-L: {res_r['rougeL']:.4f}, METEOR: {res_m['meteor']:.4f}\")\n",
    "        \n",
    "        print(\"_\" * 100)\n",
    "\n",
    "    # Compute averages\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    bleu1_score /= len(dataloader)\n",
    "    bleu2_score /= len(dataloader)\n",
    "    rouge_score /= len(dataloader)\n",
    "    meteor_score /= len(dataloader)\n",
    "\n",
    "    print(f\"BLEU-1: {bleu1_score:.4f}, BLEU-2: {bleu2_score:.4f}, ROUGE-L: {rouge_score:.4f}, METEOR: {meteor_score:.4f}\")\n",
    "\n",
    "    return total_loss / len(dataloader), 100\n",
    "\n",
    "\n",
    "def eval_epoch(model, crit, dataloader):\n",
    "    total_loss = 0.0\n",
    "\n",
    "    bleu1_score = 0\n",
    "    bleu2_score = 0\n",
    "    rouge_score = 0\n",
    "    meteor_score = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, captions in dataloader:\n",
    "            imgs, captions = imgs.to(DEVICE), captions.to(DEVICE)\n",
    "            outputs = model(imgs)\n",
    "            loss = crit(outputs, captions)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            _, predicted = outputs.max(1)\n",
    "            \n",
    "            decoded_refs = [clean_text(decode_caption(caption.cpu().numpy(), chars)) for caption in captions]\n",
    "            decoded_preds = [clean_text(decode_caption(pred.cpu().numpy(), chars)) for pred in predicted]\n",
    "            \n",
    "            # print(f\"Ref: {decoded_refs}\")\n",
    "            # print(f\"Pred: {decoded_preds}\")\n",
    "            if is_empty_prediction(decoded_preds):\n",
    "                continue\n",
    "            \n",
    "            bleu1 = bleu.compute(predictions=decoded_preds, references=[[ref] for ref in decoded_refs], max_order=1)\n",
    "            bleu2 = bleu.compute(predictions=decoded_preds, references=[[ref] for ref in decoded_refs], max_order=2)\n",
    "            res_r = rouge.compute(predictions=decoded_preds, references=decoded_refs)\n",
    "            res_m = meteor.compute(predictions=decoded_preds, references=decoded_refs)\n",
    "\n",
    "            # Accumulate scores\n",
    "            bleu1_score += bleu1[\"bleu\"]\n",
    "            bleu2_score += bleu2[\"bleu\"]\n",
    "            rouge_score += res_r[\"rougeL\"]\n",
    "            meteor_score += res_m[\"meteor\"]\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    bleu1_score /= len(dataloader)\n",
    "    bleu2_score /= len(dataloader)\n",
    "    rouge_score /= len(dataloader)\n",
    "    meteor_score /= len(dataloader)\n",
    "\n",
    "    return avg_loss, bleu1_score, bleu2_score, rouge_score, meteor_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f0fce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ce8f996d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.0012\n",
      "BLEU-2: 0.0000\n",
      "ROUGE-L: 0.0024\n",
      "METEOR: 0.0012\n"
     ]
    }
   ],
   "source": [
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "batch_size = 8\n",
    "data_test = Data(data, partitions['test'])   \n",
    "dataloader_test = DataLoader(data_test, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "model = Model().to(DEVICE)\n",
    "model.load_state_dict(torch.load(f\"models/best_model.pth\", map_location=DEVICE))\n",
    "\n",
    "avg_loss, bleu1_score, bleu2_score, rouge_score, meteor_score = eval_epoch(model, crit, dataloader_test)\n",
    "print(f\"BLEU-1: {bleu1_score:.4f}\")\n",
    "print(f\"BLEU-2: {bleu2_score:.4f}\")      \n",
    "print(f\"ROUGE-L: {rouge_score:.4f}\")\n",
    "print(f\"METEOR: {meteor_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127e547f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.0001\n",
      "BLEU-2: 0.0000\n",
      "ROUGE-L: 0.0000\n",
      "METEOR: 0.0012\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(DEVICE)  # Do NOT load weights\n",
    "\n",
    "avg_loss, bleu1_score, bleu2_score, rouge_score, meteor_score = eval_epoch(model, crit, dataloader_test)\n",
    "\n",
    "print(f\"BLEU-1: {bleu1_score:.4f}\")\n",
    "print(f\"BLEU-2: {bleu2_score:.4f}\")      \n",
    "print(f\"ROUGE-L: {rouge_score:.4f}\")\n",
    "print(f\"METEOR: {meteor_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63ebc31b",
   "metadata": {},
   "source": [
    "# Experiments (ResNet-18 & LSTM Decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f4263fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import ResNetModel\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.resnet = ResNetModel.from_pretrained('microsoft/resnet-18').to(DEVICE)\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((1, 1))  # Better pooling\n",
    "\n",
    "        self.lstm = nn.LSTM(512, 512, num_layers=3, dropout=0.3, bidirectional=True)  # 3-layer Bi-LSTM\n",
    "        self.proj = nn.Linear(1024, NUM_CHAR)  # Adjust for bidirectional output\n",
    "        self.embed = nn.Embedding(NUM_CHAR, 512)\n",
    "        self.num_classes = NUM_CHAR\n",
    "\n",
    "        # Trainable LSTM hidden state\n",
    "        self.hidden_init = nn.Parameter(torch.zeros(3 * 2, 1, 512))  # (num_layers * 2, batch, hidden_size)\n",
    "        self.cell_init = nn.Parameter(torch.zeros(3 * 2, 1, 512))\n",
    "\n",
    "        self.layer_norm = nn.LayerNorm(1024)  # Normalize LSTM outputs\n",
    "\n",
    "    def forward(self, img, captions=None, teacher_forcing_ratio=0.5):\n",
    "        batch_size = img.shape[0]\n",
    "        feat = self.resnet(img).last_hidden_state  # Use full feature maps\n",
    "        feat = self.adaptive_pool(feat).squeeze(-1).squeeze(-1).unsqueeze(0)  # (1, batch, 512)\n",
    "\n",
    "        start_token = torch.full((batch_size,), char2idx['<SOS>'], dtype=torch.long, device=DEVICE)\n",
    "        start_embed = self.embed(start_token).unsqueeze(0)  # (1, batch, 512)\n",
    "\n",
    "        hidden = self.hidden_init.expand(-1, batch_size, -1).contiguous()  # Expand for batch size\n",
    "        cell = self.cell_init.expand(-1, batch_size, -1).contiguous()\n",
    "\n",
    "        inp = start_embed\n",
    "        outputs = []\n",
    "\n",
    "        for t in range(TEXT_MAX_LEN):\n",
    "            out, (hidden, cell) = self.lstm(inp, (hidden, cell))\n",
    "            out = self.layer_norm(out)  # Apply layer normalization\n",
    "            logits = self.proj(out[-1])  # (batch, NUM_CHAR)\n",
    "\n",
    "            outputs.append(logits.unsqueeze(1))\n",
    "\n",
    "            # Scheduled Sampling: Reduce teacher forcing ratio gradually\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            if captions is not None and teacher_force:\n",
    "                inp = self.embed(captions[:, t]).unsqueeze(0)\n",
    "            else:\n",
    "                pred = logits.argmax(dim=1)\n",
    "                inp = self.embed(pred).unsqueeze(0)\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)  # (batch, seq_len, NUM_CHAR)\n",
    "        return outputs.permute(0, 2, 1)  # (batch, NUM_CHAR, seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1f83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()\n",
    "\n",
    "# wandb.init(project=\"C5_W3\")\n",
    "\n",
    "train(20)\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18069341",
   "metadata": {},
   "outputs": [],
   "source": [
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "batch_size = 8\n",
    "data_test = Data(data, partitions['test'])   \n",
    "dataloader_test = DataLoader(data_test, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "model_list = [1, 3, 4, 6, 7, 11, 12, 14, 15, 16, 19]\n",
    "for idx in model_list:\n",
    "    print(f\"models/lstm_20/best_model_{idx}.pth\")\n",
    "\n",
    "    model = Model().to(DEVICE)\n",
    "    model.load_state_dict(torch.load(f\"models/lstm_20/best_model_{idx}.pth\", map_location=DEVICE))\n",
    "\n",
    "    avg_loss, bleu1_score, bleu2_score, rouge_score, meteor_score = eval_epoch(model, crit, dataloader_test)\n",
    "    print(f\"BLEU-1: {bleu1_score:.4f}\")\n",
    "    print(f\"BLEU-2: {bleu2_score:.4f}\")      \n",
    "    print(f\"ROUGE-L: {rouge_score:.4f}\")\n",
    "    print(f\"METEOR: {meteor_score:.4f}\")\n",
    "    print(50 * \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0da7e3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU-1: 0.0004\n",
      "BLEU-2: 0.0000\n",
      "ROUGE-L: 0.0001\n",
      "METEOR: 0.0011\n"
     ]
    }
   ],
   "source": [
    "model = Model().to(DEVICE)  # Do NOT load weights\n",
    "\n",
    "avg_loss, bleu1_score, bleu2_score, rouge_score, meteor_score = eval_epoch(model, crit, dataloader_test)\n",
    "\n",
    "print(f\"BLEU-1: {bleu1_score:.4f}\")\n",
    "print(f\"BLEU-2: {bleu2_score:.4f}\")      \n",
    "print(f\"ROUGE-L: {rouge_score:.4f}\")\n",
    "print(f\"METEOR: {meteor_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "43359f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8fc41cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wandb.init(project=\"C5_W3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a458390",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
